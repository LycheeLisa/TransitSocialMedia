{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import string\n",
    "import numpy as np\n",
    "import spacy\n",
    "from html.parser import HTMLParser\n",
    "from spacy.lang.en import English\n",
    "import nltk\n",
    "from nltk import pos_tag\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "from nltk import ngrams\n",
    "import re\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import pyLDAvis.gensim\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.models.wrappers import LdaMallet\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser \n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import datetime as dt\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer as SIA\n",
    "import seaborn as sns; sns.set_style(\"whitegrid\"); sns.set_palette(\"Set2\")\n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('C:/Users/josh.a.peters/TransitSocialMedia/Data/reddit_df_topics.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['topic'] = df['topic'] + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x26137213550>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df['topic_pct'].hist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    14172\n",
       "4    11335\n",
       "8     2576\n",
       "5     2052\n",
       "3     1853\n",
       "7     1482\n",
       "9      808\n",
       "1      420\n",
       "2      387\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_topics = df[df['topic_pct'] > 0.5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12072"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(top_topics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6    6319\n",
       "4    3909\n",
       "8     573\n",
       "3     464\n",
       "5     459\n",
       "7     220\n",
       "9      74\n",
       "1      36\n",
       "2      18\n",
       "Name: topic, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_topics['topic'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "df[\"body_clean\"] = df[\"body\"].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = clean_html(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.to_csv('C:/Users/josh.a.peters/Desktop/df_topics_updated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean['title_clean'] = df[\"body\"].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>raise property tax</td>\n",
       "      <td>0.008777</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>they re go</td>\n",
       "      <td>0.007393</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>public transit system</td>\n",
       "      <td>0.007366</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>use public transit</td>\n",
       "      <td>0.007045</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>transit tax credit</td>\n",
       "      <td>0.006639</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>gas station owner</td>\n",
       "      <td>0.005626</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>low income people</td>\n",
       "      <td>0.005230</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>https enwikipediaorg wiki</td>\n",
       "      <td>0.004893</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>we re go</td>\n",
       "      <td>0.004623</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>land transfer tax</td>\n",
       "      <td>0.004318</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>property tax increase</td>\n",
       "      <td>0.004183</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>force gas station</td>\n",
       "      <td>0.003910</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>cap and trade</td>\n",
       "      <td>0.003630</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>system north america</td>\n",
       "      <td>0.003515</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>transit system north</td>\n",
       "      <td>0.003055</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         term     tfidf  counts\n",
       "0          raise property tax  0.008777      27\n",
       "1                  they re go  0.007393      19\n",
       "2       public transit system  0.007366      21\n",
       "3          use public transit  0.007045      20\n",
       "4          transit tax credit  0.006639      18\n",
       "5           gas station owner  0.005626      16\n",
       "6           low income people  0.005230      15\n",
       "7   https enwikipediaorg wiki  0.004893      23\n",
       "8                    we re go  0.004623      14\n",
       "9           land transfer tax  0.004318      13\n",
       "10      property tax increase  0.004183      12\n",
       "11          force gas station  0.003910      12\n",
       "12              cap and trade  0.003630      13\n",
       "13       system north america  0.003515      14\n",
       "14       transit system north  0.003055      13"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getTFIDFandCount(df_clean[df_clean['topic'] == 8]['body_clean'], (3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>they re go</td>\n",
       "      <td>0.002867</td>\n",
       "      <td>34</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ttc bus driver</td>\n",
       "      <td>0.002215</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>couple year ago</td>\n",
       "      <td>0.001985</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>take go train</td>\n",
       "      <td>0.001897</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>gas station owner</td>\n",
       "      <td>0.001861</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>use public transit</td>\n",
       "      <td>0.001772</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>we re go</td>\n",
       "      <td>0.001772</td>\n",
       "      <td>23</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>take public transit</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>ttc fare inspector</td>\n",
       "      <td>0.001683</td>\n",
       "      <td>20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>ve never see</td>\n",
       "      <td>0.001657</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>think they re</td>\n",
       "      <td>0.001636</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>st clair west</td>\n",
       "      <td>0.001595</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>shopper drug mart</td>\n",
       "      <td>0.001569</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>dundas west station</td>\n",
       "      <td>0.001545</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>really really really</td>\n",
       "      <td>0.000177</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    term     tfidf  counts\n",
       "0             they re go  0.002867      34\n",
       "1         ttc bus driver  0.002215      26\n",
       "2        couple year ago  0.001985      23\n",
       "3          take go train  0.001897      22\n",
       "4      gas station owner  0.001861      22\n",
       "5     use public transit  0.001772      21\n",
       "6               we re go  0.001772      23\n",
       "7    take public transit  0.001683      20\n",
       "8     ttc fare inspector  0.001683      20\n",
       "9           ve never see  0.001657      19\n",
       "10         think they re  0.001636      19\n",
       "11         st clair west  0.001595      18\n",
       "12     shopper drug mart  0.001569      18\n",
       "13   dundas west station  0.001545      18\n",
       "14  really really really  0.000177      52"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getTFIDFandCount(df_clean[df_clean['topic'] == 4]['body_clean'], (3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>term</th>\n",
       "      <th>tfidf</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>high suicide rate</td>\n",
       "      <td>0.010146</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>take public transit</td>\n",
       "      <td>0.009547</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>mental health issue</td>\n",
       "      <td>0.008876</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>late term abortion</td>\n",
       "      <td>0.008872</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adult gender identity</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>process sex reassignment</td>\n",
       "      <td>0.003648</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>provide basic necessity</td>\n",
       "      <td>0.003358</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>sex reassignment surgery</td>\n",
       "      <td>0.003126</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>suggest sex reassignment</td>\n",
       "      <td>0.002985</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>basic necessity life</td>\n",
       "      <td>0.002908</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>reassignment treatment transsexualism</td>\n",
       "      <td>0.002591</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>hour per week</td>\n",
       "      <td>0.002387</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>difficulty report participant</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>reassignment surgery qualitative</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>reassignment therapy psychopathology</td>\n",
       "      <td>0.001824</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     term     tfidf  counts\n",
       "0                       high suicide rate  0.010146       5\n",
       "1                     take public transit  0.009547       4\n",
       "2                     mental health issue  0.008876       5\n",
       "3                      late term abortion  0.008872       8\n",
       "4                   adult gender identity  0.003648       6\n",
       "5                process sex reassignment  0.003648       6\n",
       "6                 provide basic necessity  0.003358       7\n",
       "7                sex reassignment surgery  0.003126       4\n",
       "8                suggest sex reassignment  0.002985       5\n",
       "9                    basic necessity life  0.002908       6\n",
       "10  reassignment treatment transsexualism  0.002591       3\n",
       "11                          hour per week  0.002387       5\n",
       "12          difficulty report participant  0.001824       3\n",
       "13       reassignment surgery qualitative  0.001824       3\n",
       "14   reassignment therapy psychopathology  0.001824       3"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "getTFIDFandCount(df_clean[df_clean['topic'] == 1]['body_clean'], (3,3))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getTFIDFandCount(df_col, ngramrange):\n",
    "    \"\"\"(DataFrame, tuple --> DataFrame)\n",
    "    Takes a column of a dataframe and the range for n-gram analysis to find the TF-IDF for each\n",
    "    n-gram in the column.\n",
    "\n",
    "    Returns a DataFrame of the top 10 n-grams, TF-IDF score, and actual count of n-gram appearance.\n",
    "    \"\"\"\n",
    "    cv=CountVectorizer(ngram_range=ngramrange, max_features=15)\n",
    "    word_count_vector=cv.fit_transform(df_col.unique())\n",
    "    feature_names = cv.get_feature_names()\n",
    "\n",
    "    # Transforming top 400 most common words to produce TF-IDF score\n",
    "    tfidf_transformer=TfidfTransformer(smooth_idf=True,use_idf=True)\n",
    "    tfidf_transformer.fit(word_count_vector)\n",
    "    tfidf_vector=tfidf_transformer.transform(word_count_vector)\n",
    "\n",
    "    # Combining TF-IDF score with the words into a dictionary\n",
    "    weights = np.asarray(tfidf_vector.mean(axis=0)).ravel().tolist()\n",
    "    df_tfidf = pd.DataFrame(weights, index=feature_names, columns=[\"tfidf\"])\n",
    "    df_tfidf = df_tfidf.sort_values(by=[\"tfidf\"],ascending=False).reset_index()\n",
    "    df_tfidf.rename(index=str, columns={\"index\": \"term\"}, inplace=True)\n",
    "\n",
    "    # Counting the actual number of occurances and appending to dictionary of word\n",
    "    # with TF-IDF value\n",
    "    count_list = word_count_vector.toarray().sum(axis=0)\n",
    "    actual_count_dict = {\"term\": feature_names, \"counts\": count_list}\n",
    "    actual_count_df = pd.DataFrame.from_records(actual_count_dict)\n",
    "    tfidf_and_count = pd.merge(df_tfidf, actual_count_df, on='term', how='left')\n",
    "    return tfidf_and_count\n",
    "\n",
    "def add_tfidf_column(full_df, month, suffix):\n",
    "    \"\"\"(DataFrame, string, string --> DataFrame)\n",
    "    Takes the filtered dataframe to generate TFIDF scores for, as well as the month\n",
    "    and suffix relating to what the dataframe has been filtered for (i.e. mental health\n",
    "    or sarcastic posts).\n",
    "\n",
    "    Returns the top 10 TFIDF for the filtered dataframe, for that month.\n",
    "    \"\"\"\n",
    "    tfidf_df = getTFIDFandCount(full_df[\"Post_Clean\"],(2, 4))\n",
    "    tfidf_df = tfidf_df[:10]\n",
    "    tfidf_df = tfidf_df.add_suffix(suffix)\n",
    "    return tfidf_df\n",
    "\n",
    "def create_monthly_tfidf(full_df):\n",
    "    \"\"\"(DataFrame --> DataFrame)\n",
    "    Taking the Reddit dataframe and combining it with the dataframe of TF-IDF values\n",
    "    so each month is matched up with the most popular TF-IDFs for that month.\n",
    "\n",
    "    Returns a dataframe with a new column for most popular TF-IDFs of that month.\n",
    "    \"\"\"\n",
    "    all_tfidf = pd.DataFrame()\n",
    "    # Filters out empty posts as well as mental health monday posts, since they\n",
    "    # skew the popular word count\n",
    "\n",
    "    full_df = full_df[~full_df[\"Post_Clean\"].isnull()]\n",
    "    full_df = full_df[~full_df[\"Post_Clean\"].str.contains(\"mental health monday\")]\n",
    "\n",
    "    # Getting the unique month and years for the reddit data and iterating through\n",
    "    # each month-year combination\n",
    "    all_time = full_df.yearmonth_sub.unique()\n",
    "    for month in all_time:\n",
    "        filtered = full_df[full_df.yearmonth_sub == month]\n",
    "        # Generate top 10 monthly TF-IDF for all posts\n",
    "        tfidf_df = getTFIDFandCount(filtered[\"Post_Clean\"],(2, 4))\n",
    "        tfidf_df = tfidf_df[:10]\n",
    "        tfidf_df[\"yearmonth_sub\"] = month\n",
    "        # Generate top 10 monthly TF-IDF for all MH posts\n",
    "        mh_filtered = filtered[filtered.mh_combined_updated > 0.7]\n",
    "        if len(mh_filtered) > 1:\n",
    "            mh_tfidf_df = add_tfidf_column(mh_filtered, month, '_mh')\n",
    "            tfidf_df = pd.concat([tfidf_df, mh_tfidf_df], axis=1, sort=True)\n",
    "        # Generate top 10 monthly TF-IDF for all sarcastic posts\n",
    "        sarc_filtered = filtered[filtered.prob_sarc > 0.8]\n",
    "        if len(sarc_filtered) > 1:\n",
    "            sarc_tfidf_df = add_tfidf_column(sarc_filtered, month, '_sarc')\n",
    "            tfidf_df = pd.concat([tfidf_df, sarc_tfidf_df], axis=1, sort=True)\n",
    "        # Adding filtered TFIDF columns to master TFIDF dataframe with the top\n",
    "        # terms for all posts\n",
    "        all_tfidf = all_tfidf.append(tfidf_df, ignore_index=True, sort=True)\n",
    "        \n",
    "    return all_tfidf\n",
    "def get_wordnet_pos(pos_tag):\n",
    "    if pos_tag.startswith('J'):\n",
    "        return wordnet.ADJ\n",
    "    elif pos_tag.startswith('V'):\n",
    "        return wordnet.VERB\n",
    "    elif pos_tag.startswith('N'):\n",
    "        return wordnet.NOUN\n",
    "    elif pos_tag.startswith('R'):\n",
    "        return wordnet.ADV\n",
    "    else:\n",
    "        return wordnet.NOUN\n",
    "\n",
    "def clean_text(text):\n",
    "    # lower text\n",
    "    text = str(text).lower()\n",
    "    # tokenize text and remove puncutation\n",
    "    text = [word.strip(string.punctuation) for word in text.split(\" \")]\n",
    "    # remove words that contain numbers\n",
    "    text = [word for word in text if not any(c.isdigit() for c in word)]\n",
    "    # remove stop words\n",
    "    stop = stopwords.words('english')\n",
    "    text = [x for x in text if x not in stop]\n",
    "    # remove empty tokens\n",
    "    text = [t for t in text if len(t) > 0]\n",
    "    # pos tag text\n",
    "    pos_tags = pos_tag(text)\n",
    "    # lemmatize text\n",
    "    text = [WordNetLemmatizer().lemmatize(t[0], get_wordnet_pos(t[1])) for t in pos_tags]\n",
    "    # remove words with only one letter\n",
    "    text = [t for t in text if len(t) > 1]\n",
    "    # join all\n",
    "    text = \" \".join(text)\n",
    "    text = re.sub(r'([.,?!*()])', \"\", text)\n",
    "    return(text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_html(df_subs_clean):\n",
    "    \"\"\"\n",
    "    (Dataframe --> DataFrame)\n",
    "    Cleans up any redit values that were not converted propoerly from html or utf - 8 when pulled from the internet\n",
    "\n",
    "    \"\"\"\n",
    "    #define class that strips html using html parser\n",
    "    class MLStripper(HTMLParser):\n",
    "        def __init__(self):\n",
    "            self.reset()\n",
    "            self.strict = False\n",
    "            self.convert_charrefs= False\n",
    "            self.fed = []\n",
    "        def handle_data(self, d):\n",
    "            self.fed.append(d)\n",
    "        def get_data(self):\n",
    "            return ''.join(self.fed)\n",
    "    #define function that calls stripper\n",
    "    def strip_tags(html):\n",
    "        s = MLStripper()\n",
    "        s.feed(html)\n",
    "        return s.get_data()\n",
    "\n",
    "\n",
    "    #apply encoding from windows to utf to get some garbage characters\n",
    "    df_subs_clean['body_clean'] = df_subs_clean['body_clean'].str.encode(\"Windows-1252\", 'ignore').str.decode('utf-8', 'ignore').str.replace('#x200B;',\"\")\n",
    "    #apply htm function\n",
    "    df_subs_clean['body_clean'] = df_subs_clean['body_clean'].astype(str).str.replace('\\n', \"\").apply(strip_tags)\n",
    "    df_subs_clean['body_clean'] = df_subs_clean['body_clean'].astype(str).str.replace('\\r', \"\").apply(strip_tags)\n",
    "\n",
    "\n",
    "    return df_subs_clean\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

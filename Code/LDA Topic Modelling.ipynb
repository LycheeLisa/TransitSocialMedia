{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import wordnet\n",
    "import nltk\n",
    "import re\n",
    "import gensim\n",
    "from gensim import corpora\n",
    "import pickle\n",
    "from collections import OrderedDict\n",
    "import pyLDAvis.gensim\n",
    "from gensim.models import CoherenceModel\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "\n",
    "import helper_functions as hf\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials, rand\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Load updated stop words list\n",
    "stop_words = pd.read_csv(r'..\\Data\\stop_words.csv')\n",
    "stop_words = set(stop_words['stop_words']) \n",
    "\n",
    "### Load station names list\n",
    "station_names = pd.read_csv(r'..\\Data\\station_names.csv')\n",
    "station = re.compile('|'.join(map(re.escape, station_names['Station'].str.lower())))\n",
    "\n",
    "photo_names = ['svg','png','jpeg','jpg', 'photo','pictures','picture','photos']\n",
    "photo = re.compile('|'.join(map(re.escape, photo_names)))   \n",
    "\n",
    "### Load mallet package\n",
    "os.environ['MALLET_HOME'] = r'..\\\\Models\\\\mallet-2.0.8' # update this path\n",
    "mallet_path = r'..\\\\Models\\\\mallet-2.0.8\\\\bin\\\\mallet' # update this path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reddit_df = pd.read_csv(r'..\\Data\\reddit_data_raw.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reddit data : 35085\n",
      "reddit data : 14034\n"
     ]
    }
   ],
   "source": [
    "print(\"reddit data :\", reddit_df.shape[0])\n",
    "working_fraction=0.4\n",
    "reddit_df=reddit_df.sample(frac=working_fraction)\n",
    "print(\"reddit data :\", reddit_df.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "jobs=8\n",
    "mp_instance=hf.mp_tokenize(df=reddit_df,\n",
    "                           target_column='body', \n",
    "                           stop_words=stop_words,\n",
    "                           station=station, \n",
    "                           photo=photo, \n",
    "                           nlp=nlp,\n",
    "                           jobs=jobs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "14034 tokenized in 126.67205238342285 sec with 8 threads\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "processed_list=mp_instance.excecute()\n",
    "end_time = time.time() - start_time\n",
    "print(\"{0} tokenized in {1} sec with {2} threads\".format(reddit_df.shape[0], end_time, jobs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_data = [i[1] for i in processed_list]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = corpora.Dictionary(text_data)\n",
    "corpus = [dictionary.doc2bow(text) for text in text_data]\n",
    "pickle.dump(corpus, open('corpus.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [2:21:51<00:00, 79.72s/it, best loss: -0.5211239729933473]  \n"
     ]
    }
   ],
   "source": [
    "model_name=\"ldamallet\" #\"ldamodel\"\n",
    "max_evals=100\n",
    "gensim_optimizer=hf.gensim_optimizer(model_name=\"ldamallet\", \n",
    "                                     model_path=mallet_path,\n",
    "                                     dictionary=dictionary, \n",
    "                                     corpus=corpus, \n",
    "                                     texts=text_data, \n",
    "                                     max_evals=max_evals)\n",
    "trials, best_model, best_score= gensim_optimizer.exceute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>alpha</th>\n",
       "      <th>num_topics</th>\n",
       "      <th>topic_threshold</th>\n",
       "      <th>loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>76.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.356735</td>\n",
       "      <td>-0.521124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>80.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.619201</td>\n",
       "      <td>-0.515409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.727374</td>\n",
       "      <td>-0.511046</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>55.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.457233</td>\n",
       "      <td>-0.508285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>123.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.830517</td>\n",
       "      <td>-0.503549</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73</th>\n",
       "      <td>117.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.731032</td>\n",
       "      <td>-0.500623</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>57</th>\n",
       "      <td>23.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.768000</td>\n",
       "      <td>-0.500333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>28.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.282597</td>\n",
       "      <td>-0.498431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>61</th>\n",
       "      <td>58.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.673723</td>\n",
       "      <td>-0.496219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>74.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>0.376585</td>\n",
       "      <td>-0.494042</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    alpha  num_topics  topic_threshold      loss\n",
       "21   76.0        12.0         0.356735 -0.521124\n",
       "70   80.0        11.0         0.619201 -0.515409\n",
       "12   16.0         9.0         0.727374 -0.511046\n",
       "34   55.0        17.0         0.457233 -0.508285\n",
       "99  123.0        10.0         0.830517 -0.503549\n",
       "73  117.0         5.0         0.731032 -0.500623\n",
       "57   23.0        13.0         0.768000 -0.500333\n",
       "11   28.0         5.0         0.282597 -0.498431\n",
       "61   58.0         5.0         0.673723 -0.496219\n",
       "66   74.0        17.0         0.376585 -0.494042"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "losses = [trials.trials[i]['result']['loss'] for i in range(len(trials.trials))]\n",
    "params = pd.DataFrame(trials.vals)\n",
    "params['loss'] = losses\n",
    "params.sort_values('loss', inplace=True)\n",
    "params.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "params.to_csv(\"hyper_parameters.csv\",index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.077*\"people\" + 0.028*\"happen\" + 0.023*\"start\" + 0.020*\"feel\" + 0.016*\"fuck\"')\n",
      "(1, '0.068*\"work\" + 0.024*\"job\" + 0.022*\"give\" + 0.018*\"call\" + 0.016*\"life\"')\n",
      "(2, '0.065*\"car\" + 0.054*\"stop\" + 0.045*\"drive\" + 0.030*\"streetcar\" + 0.027*\"driver\"')\n",
      "(3, '0.055*\"presto\" + 0.043*\"fare\" + 0.037*\"card\" + 0.033*\"system\" + 0.023*\"pass\"')\n",
      "(4, '0.082*\"people\" + 0.078*\"pay\" + 0.046*\"cost\" + 0.043*\"money\" + 0.028*\"increase\"')\n",
      "(5, '0.036*\"government\" + 0.027*\"ontario\" + 0.023*\"province\" + 0.022*\"cut\" + 0.020*\"fund\"')\n",
      "(6, '0.053*\"live\" + 0.042*\"build\" + 0.038*\"area\" + 0.033*\"place\" + 0.030*\"downtown\"')\n",
      "(7, '0.064*\"urllink\" + 0.044*\"plan\" + 0.034*\"ford\" + 0.014*\"vote\" + 0.012*\"free\"')\n",
      "(8, '0.208*\"transit\" + 0.114*\"city\" + 0.098*\"toronto\" + 0.050*\"public\" + 0.033*\"system\"')\n",
      "(9, '0.182*\"ttc\" + 0.086*\"bus\" + 0.041*\"hour\" + 0.035*\"service\" + 0.030*\"run\"')\n",
      "(10, '0.032*\"point\" + 0.027*\"find\" + 0.017*\"issue\" + 0.014*\"case\" + 0.013*\"number\"')\n",
      "(11, '0.253*\"ttcstation\" + 0.134*\"subway\" + 0.061*\"train\" + 0.020*\"exist\" + 0.020*\"lrt\"')\n"
     ]
    }
   ],
   "source": [
    "topics = best_model.print_topics(num_words=5)\n",
    "for topic in topics:\n",
    "    print(topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "lda = gensim.models.ldamodel.LdaModel.load('..\\Models\\model5.gensim')\n",
    "lda_display = pyLDAvis.gensim.prepare(lda, corpus, dictionary, sort_topics=False)\n",
    "pyLDAvis.display(lda_display)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ldamodel.save('..\\Models\\model5.gensim')\n",
    "#pyLDAvis.save_html(lda_display, '..\\Visualisations\\5 topics.html')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

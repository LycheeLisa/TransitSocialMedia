{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test 2: Hot & New restaurants\n",
    "Target: https://www.yelp.ca/search?attrs=NewBusiness&find_loc=Toronto%2C+ON\n",
    "\n",
    "Referenced Tutorials: \n",
    "https://www.youtube.com/watch?v=ng2o98k983k&t=1150s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: beautifulsoup4 in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (4.7.1)\n",
      "Requirement already satisfied: soupsieve>=1.2 in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from beautifulsoup4) (1.8)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install beautifulsoup4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lxml in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (4.3.4)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install lxml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (2.22.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests) (2019.6.16)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from requests) (1.24.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scrapy in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (1.7.3)\n",
      "Requirement already satisfied: six>=1.5.2 in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from scrapy) (1.12.0)\n",
      "Requirement already satisfied: pyOpenSSL in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from scrapy) (19.0.0)\n",
      "Requirement already satisfied: w3lib>=1.17.0 in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from scrapy) (1.21.0)\n",
      "Requirement already satisfied: queuelib in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from scrapy) (1.5.0)\n",
      "Requirement already satisfied: PyDispatcher>=2.0.5 in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from scrapy) (2.0.5)\n",
      "Requirement already satisfied: cssselect>=0.9 in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from scrapy) (1.1.0)\n",
      "Requirement already satisfied: lxml; python_version != \"3.4\" in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from scrapy) (4.3.4)\n",
      "Requirement already satisfied: service-identity in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from scrapy) (18.1.0)\n",
      "Requirement already satisfied: parsel>=1.5 in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from scrapy) (1.5.2)\n",
      "Requirement already satisfied: Twisted>=13.1.0; python_version != \"3.4\" in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from scrapy) (19.7.0)\n",
      "Requirement already satisfied: cryptography>=2.3 in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from pyOpenSSL->scrapy) (2.7)\n",
      "Requirement already satisfied: pyasn1 in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from service-identity->scrapy) (0.4.7)\n",
      "Requirement already satisfied: attrs>=16.0.0 in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from service-identity->scrapy) (19.1.0)\n",
      "Requirement already satisfied: pyasn1-modules in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from service-identity->scrapy) (0.2.6)\n",
      "Requirement already satisfied: zope.interface>=4.4.2 in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from Twisted>=13.1.0; python_version != \"3.4\"->scrapy) (4.6.0)\n",
      "Requirement already satisfied: hyperlink>=17.1.1 in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from Twisted>=13.1.0; python_version != \"3.4\"->scrapy) (19.0.0)\n",
      "Requirement already satisfied: incremental>=16.10.1 in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from Twisted>=13.1.0; python_version != \"3.4\"->scrapy) (17.5.0)\n",
      "Requirement already satisfied: constantly>=15.1 in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from Twisted>=13.1.0; python_version != \"3.4\"->scrapy) (15.1.0)\n",
      "Requirement already satisfied: PyHamcrest>=1.9.0 in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from Twisted>=13.1.0; python_version != \"3.4\"->scrapy) (1.9.0)\n",
      "Requirement already satisfied: Automat>=0.3.0 in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from Twisted>=13.1.0; python_version != \"3.4\"->scrapy) (0.7.0)\n",
      "Requirement already satisfied: asn1crypto>=0.21.0 in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from cryptography>=2.3->pyOpenSSL->scrapy) (0.24.0)\n",
      "Requirement already satisfied: cffi!=1.11.3,>=1.8 in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from cryptography>=2.3->pyOpenSSL->scrapy) (1.12.3)\n",
      "Requirement already satisfied: setuptools in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from zope.interface>=4.4.2->Twisted>=13.1.0; python_version != \"3.4\"->scrapy) (41.0.1)\n",
      "Requirement already satisfied: idna>=2.5 in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from hyperlink>=17.1.1->Twisted>=13.1.0; python_version != \"3.4\"->scrapy) (2.8)\n",
      "Requirement already satisfied: pycparser in c:\\users\\raffles.h.koh\\appdata\\local\\continuum\\anaconda3\\lib\\site-packages (from cffi!=1.11.3,>=1.8->cryptography>=2.3->pyOpenSSL->scrapy) (2.19)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Importing BeautifulSoup\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "import csv\n",
    "import scrapy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get source code from Page1\n",
    "source = requests.get('https://www.yelp.ca/search?attrs=NewBusiness&find_loc=Toronto%2C%20ON&start=0').text\n",
    "\n",
    "soup1 = BeautifulSoup(source, 'lxml')\n",
    "\n",
    "#Confirmed, response object returns from BeautifulSoup. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tiger Sugar\n",
      "348A Yonge Street\n",
      "Bubble Tea\n",
      "4\n",
      "Chick-fil-A\n",
      "709 Yonge Street\n",
      "Fast Food\n",
      "4.5\n",
      "Phat Kaphrao\n",
      "3016B Bathurst Street\n",
      "Thai\n",
      "4.5\n",
      "Azkadenya - Mezza Diner\n",
      "235 Queen Street West\n",
      "Middle Eastern\n",
      "4.5\n",
      "EAT BKK\n",
      "580 Queen Street W\n",
      "Thai\n",
      "4.5\n",
      "Centrale Bergham\n",
      "482 Queen Street W\n",
      "Burgers\n",
      "4.5\n",
      "Bubble Lee\n",
      "469 Queen St W\n",
      "Bubble Tea\n",
      "3.5\n",
      "Xing Fu Tang\n",
      "506 Yonge Street\n",
      "Bubble Tea\n",
      "3.5\n",
      "Vicino Italian Kitchen\n",
      "146 Sumach St\n",
      "Italian\n",
      "5\n",
      "RYUS Noodle Bar\n",
      "669 Queen Street W\n",
      "Ramen\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#CSV Writer (Needs to be before for loop...)\n",
    "#CSV Writer also has a line at the end of the for loop\n",
    "\n",
    "filename = \"HotAndNew.csv\"\n",
    "f = open(filename, 'w', encoding=\"utf-8\")\n",
    "\n",
    "headers = \"restaurant, category, stars, location\" + '\\n'\n",
    "\n",
    "f.write(headers)\n",
    "\n",
    "#Find table with restaurant names and locations. \n",
    "# For loop for ALL restuarants on the list.\n",
    "#Indent pulls for for loop\n",
    "\n",
    "\n",
    "for div in soup1.find_all('div', class_='lemon--div__373c0__1mboc largerScrollablePhotos__373c0__3FEIJ arrange__373c0__UHqhV border-color--default__373c0__2oFDT'):\n",
    "    try:\n",
    "        #Take restaurant name\n",
    "        restaurant = div.a.text\n",
    "        print(restaurant)\n",
    "        #Take restaurant location\n",
    "        location = div.address.text\n",
    "        print(location)\n",
    "        #Take restaurant category\n",
    "        category = div.find('div', class_='lemon--div__373c0__1mboc priceCategory__373c0__3zW0R display--inline-block__373c0__2de_K border-color--default__373c0__2oFDT').a.contents\n",
    "        print(category[0])\n",
    "        #Take Restaurant Ratings\n",
    "        arialabel = div.find('span', class_='lemon--span__373c0__3997G display--inline__373c0__1DbOG border-color--default__373c0__2oFDT').contents\n",
    "        stars = str(arialabel)\n",
    "        star = stars[18:27]\n",
    "        final = star.split()\n",
    "        print(final[0])\n",
    "\n",
    "    #skip comment tables\n",
    "    except:\n",
    "        print('')\n",
    "    \n",
    "#Write to 2 columns\n",
    "\n",
    "\n",
    "    f.write(restaurant +','+ str(category[0]) +','+ final[0] + ','+ location+'\\n')\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get source code from Page2\n",
    "source = requests.get('https://www.yelp.ca/search?attrs=NewBusiness&find_loc=Toronto%2C%20ON&start=10').text\n",
    "\n",
    "soup2 = BeautifulSoup(source, 'lxml')\n",
    "\n",
    "#Confirmed, response object returns from BeautifulSoup. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Nani’s Gelato\n",
      "\n",
      "Bloom\n",
      "596 Yonge street\n",
      "Cafes\n",
      "4\n",
      "Bluestone Lane\n",
      "2 Queen St E\n",
      "Coffee & Tea\n",
      "5\n",
      "Sisters & Co\n",
      "887 Dundas Street West\n",
      "Breakfast & Brunch\n",
      "4\n",
      "Avelo\n",
      "51 St Nicholas Street\n",
      "Vegan\n",
      "4.5\n",
      "Buono\n",
      "354 Queen Street W\n",
      "Italian\n",
      "4\n",
      "The Alley\n",
      "382 Yonge Street\n",
      "Bubble Tea\n",
      "5\n",
      "Roselle West\n",
      "108 Dovercourt Rd\n",
      "Desserts\n",
      "4.5\n",
      "TRU TEA 初茶\n",
      "25 Carlton Street\n",
      "Bubble Tea\n",
      "4\n",
      "Favorites\n",
      "141 Ossington Avenue\n",
      "Salad\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#CSV Writer (Needs to be before for loop...)\n",
    "#CSV Writer also has a line at the end of the for loop\n",
    "\n",
    "filename = \"HotAndNew.csv\"\n",
    "f = open(filename, 'a+', encoding=\"utf-8\")\n",
    "\n",
    "#Find table with restaurant names and locations. \n",
    "# For loop for ALL restuarants on the list.\n",
    "#Indent pulls for for loop\n",
    "\n",
    "\n",
    "for div in soup2.find_all('div', class_='lemon--div__373c0__1mboc largerScrollablePhotos__373c0__3FEIJ arrange__373c0__UHqhV border-color--default__373c0__2oFDT'):\n",
    "    try:\n",
    "        #Take restaurant name\n",
    "        restaurant = div.a.text\n",
    "        print(restaurant)\n",
    "        #Take restaurant location\n",
    "        location = div.address.text\n",
    "        print(location)\n",
    "        #Take restaurant category\n",
    "        category = div.find('div', class_='lemon--div__373c0__1mboc priceCategory__373c0__3zW0R display--inline-block__373c0__2de_K border-color--default__373c0__2oFDT').a.contents\n",
    "        print(category[0])\n",
    "        #Take Restaurant Ratings\n",
    "        arialabel = div.find('span', class_='lemon--span__373c0__3997G display--inline__373c0__1DbOG border-color--default__373c0__2oFDT').contents\n",
    "        stars = str(arialabel)\n",
    "        star = stars[18:27]\n",
    "        final = star.split()\n",
    "        print(final[0])\n",
    "    #skip comment tables\n",
    "    except:\n",
    "        print('')\n",
    "    \n",
    "#Write to 2 columns\n",
    "\n",
    "\n",
    "    f.write(restaurant +','+ str(category[0]) +','+ final[0] + ','+ location+'\\n')\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get source code from Page3\n",
    "source = requests.get('https://www.yelp.ca/search?attrs=NewBusiness&find_loc=Toronto%2C%20ON&start=20').text\n",
    "\n",
    "soup3 = BeautifulSoup(source, 'lxml')\n",
    "\n",
    "#Confirmed, response object returns from BeautifulSoup. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cass Avenue\n",
      "150 Eglinton Avenue E\n",
      "Cocktail Bars\n",
      "4.5\n",
      "Boat King of Thai Noodles\n",
      "770 Bay Street\n",
      "Thai\n",
      "3\n",
      "Meet Fresh\n",
      "333 Spadina Avenue\n",
      "Shaved Snow\n",
      "4\n",
      "BAO\n",
      "2-270 Spadina Avenue\n",
      "Chinese\n",
      "3\n",
      "L’ARC EN CIEL\n",
      "376 College Street\n",
      "Desserts\n",
      "4.5\n",
      "Avling Kitchen & Brewery\n",
      "1042 Queen Street E\n",
      "Brewpubs\n",
      "4\n",
      "Mascot Brewery Patio\n",
      "220 KING STREET WEST\n",
      "Breweries\n",
      "4\n",
      "Hiwa\n",
      "64 Edward St\n",
      "Chinese\n",
      "4\n",
      "Kung Fu Tea\n",
      "633 Bloor St W\n",
      "Bubble Tea\n",
      "4.5\n",
      "Li Bu Gou\n",
      "10 Willison Square\n",
      "Chinese\n",
      "4\n"
     ]
    }
   ],
   "source": [
    "#CSV Writer (Needs to be before for loop...)\n",
    "#CSV Writer also has a line at the end of the for loop\n",
    "\n",
    "filename = \"HotAndNew.csv\"\n",
    "f = open(filename, 'a+', encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "#Find table with restaurant names and locations. \n",
    "# For loop for ALL restuarants on the list.\n",
    "#Indent pulls for for loop\n",
    "\n",
    "\n",
    "for div in soup3.find_all('div', class_='lemon--div__373c0__1mboc largerScrollablePhotos__373c0__3FEIJ arrange__373c0__UHqhV border-color--default__373c0__2oFDT'):\n",
    "    try:\n",
    "        #Take restaurant name\n",
    "        restaurant = div.a.text\n",
    "        print(restaurant)\n",
    "        #Take restaurant location\n",
    "        location = div.address.text\n",
    "        print(location)\n",
    "        #Take restaurant category\n",
    "        category = div.find('div', class_='lemon--div__373c0__1mboc priceCategory__373c0__3zW0R display--inline-block__373c0__2de_K border-color--default__373c0__2oFDT').a.contents\n",
    "        print(category[0])\n",
    "        #Take Restaurant Ratings\n",
    "        arialabel = div.find('span', class_='lemon--span__373c0__3997G display--inline__373c0__1DbOG border-color--default__373c0__2oFDT').contents\n",
    "        stars = str(arialabel)\n",
    "        star = stars[18:27]\n",
    "        final = star.split()\n",
    "        print(final[0])\n",
    "    #skip comment tables\n",
    "    except:\n",
    "        print('')\n",
    "    \n",
    "#Write to 2 columns\n",
    "\n",
    "\n",
    "    f.write(restaurant +','+ str(category[0]) +','+ final[0] + ','+ location+'\\n')\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get source code from Page4\n",
    "source = requests.get('https://www.yelp.ca/search?attrs=NewBusiness&find_loc=Toronto%2C%20ON&start=30').text\n",
    "\n",
    "soup4 = BeautifulSoup(source, 'lxml')\n",
    "\n",
    "#Confirmed, response object returns from BeautifulSoup. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Par-Tee Putt\n",
      "26 Duncan Street\n",
      "Golf\n",
      "3\n",
      "San Coffee Room\n",
      "135 Ossington Avenue\n",
      "Coffee & Tea\n",
      "5\n",
      "The Fourth Man in the Fire\n",
      "832 Dundas Street W\n",
      "Pizza\n",
      "3.5\n",
      "Bar Poet\n",
      "1090 Queen Street W\n",
      "Bars\n",
      "3\n",
      "Gyubee Japanese Grill - Dundas\n",
      "157 Dundas St W\n",
      "Japanese\n",
      "5\n",
      "Project Glyph\n",
      "40 Hayden Street\n",
      "Desserts\n",
      "5\n",
      "Heart Clean Eats\n",
      "113 Fort York Boulevard\n",
      "Coffee & Tea\n",
      "5\n",
      "Les epicuriens\n",
      "2109 1/2 Yonge Street\n",
      "Ice Cream & Frozen Yogurt\n",
      "4\n",
      "The Sweet Oven\n",
      "1911 Queen Street E\n",
      "Bakeries\n",
      "4\n",
      "Higher\n",
      "493A Dundas St W\n",
      "Bubble Tea\n",
      "3.5\n"
     ]
    }
   ],
   "source": [
    "#CSV Writer (Needs to be before for loop...)\n",
    "#CSV Writer also has a line at the end of the for loop\n",
    "\n",
    "filename = \"HotAndNew.csv\"\n",
    "f = open(filename, 'a+', encoding=\"utf-8\")\n",
    "\n",
    "#Find table with restaurant names and locations. \n",
    "# For loop for ALL restuarants on the list.\n",
    "#Indent pulls for for loop\n",
    "\n",
    "\n",
    "for div in soup4.find_all('div', class_='lemon--div__373c0__1mboc largerScrollablePhotos__373c0__3FEIJ arrange__373c0__UHqhV border-color--default__373c0__2oFDT'):\n",
    "    try:\n",
    "        #Take restaurant name\n",
    "        restaurant = div.a.text\n",
    "        print(restaurant)\n",
    "        #Take restaurant location\n",
    "        location = div.address.text\n",
    "        print(location)\n",
    "        #Take restaurant category\n",
    "        category = div.find('div', class_='lemon--div__373c0__1mboc priceCategory__373c0__3zW0R display--inline-block__373c0__2de_K border-color--default__373c0__2oFDT').a.contents\n",
    "        print(category[0])\n",
    "        #Take Restaurant Ratings\n",
    "        arialabel = div.find('span', class_='lemon--span__373c0__3997G display--inline__373c0__1DbOG border-color--default__373c0__2oFDT').contents\n",
    "        stars = str(arialabel)\n",
    "        star = stars[18:27]\n",
    "        final = star.split()\n",
    "        print(final[0])\n",
    "    #skip comment tables\n",
    "    except:\n",
    "        print('')\n",
    "    \n",
    "#Write to 2 columns\n",
    "\n",
    "\n",
    "    f.write(restaurant +','+ str(category[0]) +','+ final[0] + ','+ location+'\\n')\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get source code from Page5\n",
    "source = requests.get('https://www.yelp.ca/search?attrs=NewBusiness&find_loc=Toronto%2C%20ON&start=40').text\n",
    "\n",
    "soup5 = BeautifulSoup(source, 'lxml')\n",
    "\n",
    "#Confirmed, response object returns from BeautifulSoup. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Gong Cha\n",
      "390 Queen Street West\n",
      "Bubble Tea\n",
      "3\n",
      "Xango\n",
      "461 King Street W\n",
      "Latin American\n",
      "3.5\n",
      "est Restaurant\n",
      "729 Queen Street E\n",
      "Canadian (New)\n",
      "3\n",
      "Best istanbul Restaurant\n",
      "235 Augusta Avenue\n",
      "Turkish\n",
      "3.5\n",
      "La Diperie\n",
      "717 Bay St\n",
      "Ice Cream & Frozen Yogurt\n",
      "3.5\n",
      "Ronin Izakaya\n",
      "39 Baldwin Street\n",
      "Japanese\n",
      "3.5\n",
      "Jollibee\n",
      "79 Billy Bishop Way\n",
      "Filipino\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "#CSV Writer (Needs to be before for loop...)\n",
    "#CSV Writer also has a line at the end of the for loop\n",
    "\n",
    "filename = \"HotAndNew.csv\"\n",
    "f = open(filename, 'a+', encoding=\"utf-8\")\n",
    "\n",
    "\n",
    "#Find table with restaurant names and locations. \n",
    "# For loop for ALL restuarants on the list.\n",
    "#Indent pulls for for loop\n",
    "\n",
    "\n",
    "for div in soup5.find_all('div', class_='lemon--div__373c0__1mboc largerScrollablePhotos__373c0__3FEIJ arrange__373c0__UHqhV border-color--default__373c0__2oFDT'):\n",
    "    try:\n",
    "        #Take restaurant name\n",
    "        restaurant = div.a.text\n",
    "        print(restaurant)\n",
    "        #Take restaurant location\n",
    "        location = div.address.text\n",
    "        print(location)\n",
    "        #Take restaurant category\n",
    "        category = div.find('div', class_='lemon--div__373c0__1mboc priceCategory__373c0__3zW0R display--inline-block__373c0__2de_K border-color--default__373c0__2oFDT').a.contents\n",
    "        print(category[0])\n",
    "        #Take Restaurant Ratings\n",
    "        arialabel = div.find('span', class_='lemon--span__373c0__3997G display--inline__373c0__1DbOG border-color--default__373c0__2oFDT').contents\n",
    "        stars = str(arialabel)\n",
    "        star = stars[18:27]\n",
    "        final = star.split()\n",
    "        print(final[0])\n",
    "    #skip comment tables\n",
    "    except:\n",
    "        print('')\n",
    "    \n",
    "#Write to 2 columns\n",
    "\n",
    "\n",
    "    f.write(restaurant +','+ str(category[0]) +','+ final[0] + ','+ location+'\\n')\n",
    "    \n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rando Code\n",
    "#Launch & Unitilize browsers\n",
    "from selenium import webdriver\n",
    "#Search for stuff\n",
    "from selenium.webdriver.common.by import By \n",
    "#Wait for page to load\n",
    "from selenium.webdriver.support.ui import WebDriverWait \n",
    "#Specify what we're looking for\n",
    "from selenium.webdriver.support import expected_conditions as EC \n",
    "#Handle timeouts\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "\n",
    "pip3 install selenium"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Get stars\n",
    "#ratings = div.find('div,', 'lemon--div__373c0__1mboc border-color--default__373c0__2oFDT').get_attribute(\"aria-label\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
